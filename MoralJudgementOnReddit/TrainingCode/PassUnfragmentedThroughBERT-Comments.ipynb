{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PassUnfragmentedThroughBERT-Comments.ipynb","provenance":[{"file_id":"1Bwdaukse9E2ZYjZG8jOkuNMS60KkVpPU","timestamp":1624282119764},{"file_id":"18U0Sv4niAisrtN1g4_LfrrRPsrQhpnJh","timestamp":1623080623395}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPPLJJVmTa5Y3MPFn3JIQU5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ajOx2WcZ_uLO"},"source":["# Procedural"]},{"cell_type":"markdown","metadata":{"id":"onNkqotk_zFo"},"source":["Mount the my drive and create a folder for the data if it doesn't already exist"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PalDdmCx_fAe","executionInfo":{"status":"ok","timestamp":1624286533705,"user_tz":-60,"elapsed":332,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"1476806b-4464-4f76-ef95-88221ae797a9"},"source":["# Mount my drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Create a folder for the data if it does not already exist\n","import os\n","if not os.path.exists('/content/drive/MyDrive/MastersProject/data/'):\n","    os.makedirs('/content/drive/MyDrive/MastersProject/data/')\n","    print(\"Created the folder!\")\n","else:\n","    print(\"Folder already existed!\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Folder already existed!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EHXD3NBE_3Rh","executionInfo":{"status":"ok","timestamp":1624286537418,"user_tz":-60,"elapsed":3331,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"66fc769f-b68f-43c7-b285-354e3079629b"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z_nZLxKc_9Hq","executionInfo":{"status":"ok","timestamp":1624286538312,"user_tz":-60,"elapsed":899,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["import transformers\n","import pandas as pd\n","import torch\n","import numpy as np\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"4h2T_rfc_-p4","executionInfo":{"status":"ok","timestamp":1624286538314,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["RANDOM_SEED = 42"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fMoE3JDpAhTN"},"source":["# Prepare the data for BERT"]},{"cell_type":"markdown","metadata":{"id":"wzRHz8D3Ax-e"},"source":["Set the hyperparameters needed for data preparation"]},{"cell_type":"code","metadata":{"id":"gd78Vo-EAkKp","executionInfo":{"status":"ok","timestamp":1624286538315,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["MODEL_NAME = \"bert-base-cased\"\n","MAX_LEN = 20\n","VALID_TEST_PROPORTION = 0.2\n","BATCH_SIZE = 16\n","TEXT_CHOSEN = \"body\"     # in {body}"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UOoMBnWaBFuK"},"source":["Read the dataset as a pandas dataframe and add a column of binary is_asshole values"]},{"cell_type":"code","metadata":{"id":"grZGRxenBFN_","executionInfo":{"status":"ok","timestamp":1624286539934,"user_tz":-60,"elapsed":1624,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["df = pd.read_csv('drive/MyDrive/MastersProject/data/clean_comments2019-2019_first_half.csv')\n","df['is_asshole'] = [1 if verdict in [\"YTA\",\"ESH\"] else 0 for verdict in df[\"verdict\"]]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"aAPxpBsK0Qzw","executionInfo":{"status":"ok","timestamp":1624286571765,"user_tz":-60,"elapsed":31833,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["# Drop from the dataframe comments whose verdict has not been deciphered\n","indices_of_unknown_verdicts = [idx for (idx, row) in df.iterrows() if row.verdict == \"UNK\"]\n","df.drop(index=indices_of_unknown_verdicts, inplace=True)\n","\n","# Set comment ids as the indices for the dataframe\n","df.set_index(\"id\", inplace=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJVB3xStxjmk","executionInfo":{"status":"ok","timestamp":1624286571767,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["# Note I need to remove the labels in the future!"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UjOi1pn1BNPm"},"source":["Specify the BERT dataset class"]},{"cell_type":"code","metadata":{"id":"hcP8QgoqBJER","executionInfo":{"status":"ok","timestamp":1624286571767,"user_tz":-60,"elapsed":13,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["class AITADataset(Dataset):\n","    # Upon onject instance creation, you feed the text samples, their targets, the tokeniser and the max length.\n","    def __init__(self, texts, targets, tokeniser, max_len):\n","        self.texts = texts\n","        self.targets = targets\n","        self.tokeniser = tokeniser\n","        self.max_len = max_len\n","        \n","    def __len__(self):\n","        return len(self.texts)\n","    \n","    # This method is called when a batch is created. \"item\" is the index of each sample to be in batch.\n","    def __getitem__(self, item):\n","        # Normally it is already a string\n","        text = str(self.texts[item])\n","\n","        # Create a dictionary constituting the encoding of the current item (i.e. current text)\n","        encoding = tokeniser(\n","            text,\n","            truncation=True,\n","            max_length=self.max_len,\n","            add_special_tokens=True,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_token_type_ids=False,\n","            return_tensors='pt')\n","        \n","        # These are unnecessary I think\n","        encoding['input_ids'] = encoding['input_ids'].flatten()\n","        encoding['attention_mask'] = encoding['attention_mask'].flatten()\n","        \n","        # In the encoding dictionary for the current text, add the target corresponding to it and the actual test\n","        dic_out = {'input_ids': encoding['input_ids'],\n","                   'attention_mask': encoding['attention_mask'],\n","                   'targets': torch.tensor(self.targets[item], dtype=torch.long),\n","                   'sample_text': text}\n","        \n","        return dic_out"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yQFyFTkVBV3q"},"source":["Make a function that creates a dataloader for BERT"]},{"cell_type":"code","metadata":{"id":"ybmH7DKyBVT4","executionInfo":{"status":"ok","timestamp":1624286571768,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["def create_data_loader(df, tokeniser, max_len, batch_size, text_chosen):\n","    '''\n","    Creates a dataset from the given dataframe and a dataloader spitting batches of the dataset\n","    '''\n","    if text_chosen == \"body\":\n","        texts = df.body.to_numpy()\n","    else:\n","        raise ValueError(\"Invalid TEXT_CHOSEN!\")\n","\n","    ds = AITADataset(\n","        texts=texts,\n","        targets=df.is_asshole.to_numpy(),\n","        tokeniser=tokeniser,\n","        max_len=max_len)\n","    \n","    dataloader = DataLoader(ds, batch_size=batch_size, num_workers=2)\n","    \n","    return dataloader"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"orS5SeVQBeVQ"},"source":["Split the dataframes"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PC9b5wQHBcZv","executionInfo":{"status":"ok","timestamp":1624286571768,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"01b9e50c-c1af-4ba7-8a50-820eb9b5ff60"},"source":["df_train, df_test_valid = train_test_split(df, test_size=VALID_TEST_PROPORTION, random_state=RANDOM_SEED)\n","df_valid, df_test = train_test_split(df_test_valid, test_size=0.5, random_state=RANDOM_SEED)\n","print(\"Train dataset:\", df_train.shape)\n","print(\"Valid dataset:\", df_valid.shape)\n","print(\"Test dataset:\", df_test.shape)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Train dataset: (218488, 6)\n","Valid dataset: (27311, 6)\n","Test dataset: (27311, 6)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-Qw7HOAc_AUZ"},"source":["Save the targets and weights of the dataset split as above"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MjA3_1PafWU-","executionInfo":{"status":"ok","timestamp":1624286571768,"user_tz":-60,"elapsed":12,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"7d58262f-1d9d-4b3d-fd41-36a32ffeff96"},"source":["y_train = torch.tensor(df_train['is_asshole'].values)\n","print(y_train[:15])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"spg1Cdrq--xC","executionInfo":{"status":"ok","timestamp":1624286571768,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["y_train = torch.tensor(df_train['is_asshole'].values)\n","torch.save(y_train, '/content/drive/MyDrive/MastersProject/BERT_outputs/Comments/y_train.pt')\n","del y_train\n","\n","y_valid = torch.tensor(df_valid['is_asshole'].values)\n","torch.save(y_valid, '/content/drive/MyDrive/MastersProject/BERT_outputs/Comments/y_valid.pt')\n","del y_valid\n","\n","y_test = torch.tensor(df_test['is_asshole'].values)\n","torch.save(y_test, '/content/drive/MyDrive/MastersProject/BERT_outputs/Comments/y_test.pt')\n","del y_test"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yhEYAEqyCkNu"},"source":["Initialise the BERT tokeniser based on the chosen model name"]},{"cell_type":"code","metadata":{"id":"6lpBIPbCCSmV","executionInfo":{"status":"ok","timestamp":1624286575923,"user_tz":-60,"elapsed":4165,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["tokeniser = transformers.BertTokenizer.from_pretrained(MODEL_NAME)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ISNXmhyHCqcC"},"source":["Create a dataloader from the small dataframe to be overfit"]},{"cell_type":"code","metadata":{"id":"oCVNJMz2CrPz","executionInfo":{"status":"ok","timestamp":1624286575925,"user_tz":-60,"elapsed":16,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["train_loader = create_data_loader(df_train, tokeniser, MAX_LEN, BATCH_SIZE, TEXT_CHOSEN)\n","valid_loader = create_data_loader(df_valid, tokeniser, MAX_LEN, BATCH_SIZE, TEXT_CHOSEN)\n","test_loader = create_data_loader(df_test, tokeniser, MAX_LEN, BATCH_SIZE, TEXT_CHOSEN)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i4dcOU87DUVO"},"source":["Inspect a batch from the dataloader"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KU9IHW-Cskm","executionInfo":{"status":"ok","timestamp":1624286575925,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"7483fe05-1179-4601-ace1-f6d28b379f32"},"source":["num_tokens_to_print_per_text = 100\n","train_data_batch = next(iter(train_loader))\n","loader_keys = train_data_batch.keys()\n","print(\"Each dataloader batch is like a dictionary with keys:\", loader_keys)\n","print(100*\"-\")\n","print(\"Shapes:\")\n","print()\n","print(\"input_ids:         \", train_data_batch['input_ids'].shape)\n","print(\"attention_mask:    \", train_data_batch['attention_mask'].shape)\n","print(\"targets:           \", train_data_batch['targets'].shape)\n","print(\"sample_text:       \", train_data_batch['targets'].shape)\n","print(100*\"-\")\n","print(\"Here are the first {} tokens of the first 5 tokenised texts in the batch:\".format(num_tokens_to_print_per_text))\n","print()\n","for i in range(0, 5):\n","  current_sample_token_ids = train_data_batch['input_ids'][i,0:num_tokens_to_print_per_text]\n","  current_sample_tokens = tokeniser.convert_ids_to_tokens(current_sample_token_ids)\n","  print(current_sample_tokens)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Each dataloader batch is like a dictionary with keys: dict_keys(['input_ids', 'attention_mask', 'targets', 'sample_text'])\n","----------------------------------------------------------------------------------------------------\n","Shapes:\n","\n","input_ids:          torch.Size([16, 20])\n","attention_mask:     torch.Size([16, 20])\n","targets:            torch.Size([16])\n","sample_text:        torch.Size([16])\n","----------------------------------------------------------------------------------------------------\n","Here are the first 100 tokens of the first 5 tokenised texts in the batch:\n","\n","['[CLS]', 'N', '##TA', 'but', 'maybe', 'consider', 'change', 'b', '##f', 'to', 'one', 'that', 'is', 'not', 'a', 'f', '##eti', '##shi', '##st', '[SEP]']\n","['[CLS]', 'N', '##A', '##H', '.', 'To', 'me', 'though', ',', 'it', \"'\", 's', 'a', 'nuclear', 'option', 'that', 'will', 'cause', 'resentment', '[SEP]']\n","['[CLS]', 'N', '##TA', 'If', 'you', 'made', 'plans', 'with', 'him', ',', 'it', \"'\", 's', 'pretty', 'shit', '##ty', 'of', 'him', 'to', '[SEP]']\n","['[CLS]', 'N', '##TA', '-', 'However', ',', 'your', 'dad', 'on', 'the', 'other', '[', 'hand', ']', '(', 'http', ':', '/', '/', '[SEP]']\n","['[CLS]', 'E', '##S', '##H', 'you', 'all', 'need', 'to', 'grow', 'up', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7MbLr0DWEZEt"},"source":["# Create BERT and send the primary data through it"]},{"cell_type":"code","metadata":{"id":"66sAnR7xO6aA","executionInfo":{"status":"ok","timestamp":1624286575926,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["BERT_OUT_CHOSEN = \"pooled\"      # in {pooled, full}"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YGauZtSlEjMg"},"source":["Use GPU if available"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9suKi99jDfgB","executionInfo":{"status":"ok","timestamp":1624286575926,"user_tz":-60,"elapsed":13,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"7edaaa6b-164a-4f7a-dc20-5b3e68a656a8"},"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","torch.cuda.empty_cache()\n","print(device)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kYnHMJY0EnpH"},"source":["Instantiate BERT using a custom configuration and freeze it"]},{"cell_type":"code","metadata":{"id":"Gt3szaceElEa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624286581307,"user_tz":-60,"elapsed":5391,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"d3780399-6cca-4903-9715-c0c28f017a04"},"source":["bert_config = transformers.BertConfig(vocab_size=28996,\n","                                      hidden_size=768,\n","                                      num_hidden_layers=12,\n","                                      num_attention_heads=12,\n","                                      max_position_embeddings=512)\n","\n","bert_model = transformers.BertModel.from_pretrained(MODEL_NAME, config=bert_config)\n","# Freeze BERT so that its weights are not further fine-tuned from their pretrained values and when samples are passed into it, grads are not stored in the RAM\n","for param in bert_model.parameters():\n","    param.requires_grad = False\n","bert_model = bert_model.to(device)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"yRYe5VcerP4f"},"source":["Get BERT's pooled output for the training/validation/test data"]},{"cell_type":"code","metadata":{"id":"2dNRt4VStQXd","executionInfo":{"status":"ok","timestamp":1624286581309,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["data_to_get = \"test\"    # In {train, test, valid}"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"35RCPRqFFqbp","executionInfo":{"status":"ok","timestamp":1624286620964,"user_tz":-60,"elapsed":39664,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"c7ed2afc-623e-49e2-f8f8-5918487ca7da"},"source":["# Choose whether to feed the batches of the train, valid or test loader to BERT\n","if data_to_get == \"test\":\n","  loader = test_loader\n","elif data_to_get == \"train\":\n","  loader = train_loader\n","elif data_to_get == \"valid\":\n","  loader = valid_loader\n","else:\n","  raise ValueError (\"Invalid data_to_get selected\")\n","\n","del test_loader\n","del train_loader\n","del valid_loader\n","\n","for i, data_batch in enumerate(loader):\n","    bert_output = bert_model(data_batch['input_ids'].to(device), data_batch['attention_mask'].to(device))\n","\n","    if i == 0:\n","        if BERT_OUT_CHOSEN == \"pooled\":\n","            X = bert_output['pooler_output']\n","        elif BERT_OUT_CHOSEN == \"full\":\n","            X = bert_output['last_hidden_state']\n","        else:\n","            raise ValueError(\"Invalid BERT_OUT_CHOSEN\")\n","    else:\n","        if BERT_OUT_CHOSEN == \"pooled\":\n","            X = torch.cat((X, bert_output['pooler_output']), 0)\n","        elif BERT_OUT_CHOSEN == \"full\":\n","            X = torch.cat((X, bert_output['last_hidden_state']), 0)\n","        else:\n","            raise ValueError(\"Invalid BERT_OUT_CHOSEN\")\n","\n","    del bert_output\n","    torch.cuda.empty_cache()\n","\n","    if (i + 1) % 10 == 0:\n","        print(\"Batch #{} through!\".format(i + 1))\n","\n","print(X.shape)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Batch #10 through!\n","Batch #20 through!\n","Batch #30 through!\n","Batch #40 through!\n","Batch #50 through!\n","Batch #60 through!\n","Batch #70 through!\n","Batch #80 through!\n","Batch #90 through!\n","Batch #100 through!\n","Batch #110 through!\n","Batch #120 through!\n","Batch #130 through!\n","Batch #140 through!\n","Batch #150 through!\n","Batch #160 through!\n","Batch #170 through!\n","Batch #180 through!\n","Batch #190 through!\n","Batch #200 through!\n","Batch #210 through!\n","Batch #220 through!\n","Batch #230 through!\n","Batch #240 through!\n","Batch #250 through!\n","Batch #260 through!\n","Batch #270 through!\n","Batch #280 through!\n","Batch #290 through!\n","Batch #300 through!\n","Batch #310 through!\n","Batch #320 through!\n","Batch #330 through!\n","Batch #340 through!\n","Batch #350 through!\n","Batch #360 through!\n","Batch #370 through!\n","Batch #380 through!\n","Batch #390 through!\n","Batch #400 through!\n","Batch #410 through!\n","Batch #420 through!\n","Batch #430 through!\n","Batch #440 through!\n","Batch #450 through!\n","Batch #460 through!\n","Batch #470 through!\n","Batch #480 through!\n","Batch #490 through!\n","Batch #500 through!\n","Batch #510 through!\n","Batch #520 through!\n","Batch #530 through!\n","Batch #540 through!\n","Batch #550 through!\n","Batch #560 through!\n","Batch #570 through!\n","Batch #580 through!\n","Batch #590 through!\n","Batch #600 through!\n","Batch #610 through!\n","Batch #620 through!\n","Batch #630 through!\n","Batch #640 through!\n","Batch #650 through!\n","Batch #660 through!\n","Batch #670 through!\n","Batch #680 through!\n","Batch #690 through!\n","Batch #700 through!\n","Batch #710 through!\n","Batch #720 through!\n","Batch #730 through!\n","Batch #740 through!\n","Batch #750 through!\n","Batch #760 through!\n","Batch #770 through!\n","Batch #780 through!\n","Batch #790 through!\n","Batch #800 through!\n","Batch #810 through!\n","Batch #820 through!\n","Batch #830 through!\n","Batch #840 through!\n","Batch #850 through!\n","Batch #860 through!\n","Batch #870 through!\n","Batch #880 through!\n","Batch #890 through!\n","Batch #900 through!\n","Batch #910 through!\n","Batch #920 through!\n","Batch #930 through!\n","Batch #940 through!\n","Batch #950 through!\n","Batch #960 through!\n","Batch #970 through!\n","Batch #980 through!\n","Batch #990 through!\n","Batch #1000 through!\n","Batch #1010 through!\n","Batch #1020 through!\n","Batch #1030 through!\n","Batch #1040 through!\n","Batch #1050 through!\n","Batch #1060 through!\n","Batch #1070 through!\n","Batch #1080 through!\n","Batch #1090 through!\n","Batch #1100 through!\n","Batch #1110 through!\n","Batch #1120 through!\n","Batch #1130 through!\n","Batch #1140 through!\n","Batch #1150 through!\n","Batch #1160 through!\n","Batch #1170 through!\n","Batch #1180 through!\n","Batch #1190 through!\n","Batch #1200 through!\n","Batch #1210 through!\n","Batch #1220 through!\n","Batch #1230 through!\n","Batch #1240 through!\n","Batch #1250 through!\n","Batch #1260 through!\n","Batch #1270 through!\n","Batch #1280 through!\n","Batch #1290 through!\n","Batch #1300 through!\n","Batch #1310 through!\n","Batch #1320 through!\n","Batch #1330 through!\n","Batch #1340 through!\n","Batch #1350 through!\n","Batch #1360 through!\n","Batch #1370 through!\n","Batch #1380 through!\n","Batch #1390 through!\n","Batch #1400 through!\n","Batch #1410 through!\n","Batch #1420 through!\n","Batch #1430 through!\n","Batch #1440 through!\n","Batch #1450 through!\n","Batch #1460 through!\n","Batch #1470 through!\n","Batch #1480 through!\n","Batch #1490 through!\n","Batch #1500 through!\n","Batch #1510 through!\n","Batch #1520 through!\n","Batch #1530 through!\n","Batch #1540 through!\n","Batch #1550 through!\n","Batch #1560 through!\n","Batch #1570 through!\n","Batch #1580 through!\n","Batch #1590 through!\n","Batch #1600 through!\n","Batch #1610 through!\n","Batch #1620 through!\n","Batch #1630 through!\n","Batch #1640 through!\n","Batch #1650 through!\n","Batch #1660 through!\n","Batch #1670 through!\n","Batch #1680 through!\n","Batch #1690 through!\n","Batch #1700 through!\n","torch.Size([27311, 768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WN9eyHR5i76S","executionInfo":{"status":"ok","timestamp":1624286621478,"user_tz":-60,"elapsed":516,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["torch.save(X, '/content/drive/MyDrive/MastersProject/BERT_outputs/Comments/X_{}_{}_{}.pt'.format(data_to_get, TEXT_CHOSEN, BERT_OUT_CHOSEN))\n","# to load: X_train_pooled = torch.load('/content/drive/MyDrive/MastersProject/BERT_outputs/X_train_pooled.pt', map_location=torch.device('cpu'))"],"execution_count":22,"outputs":[]}]}