{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PassFragmentedThroughBERT.ipynb","provenance":[{"file_id":"18U0Sv4niAisrtN1g4_LfrrRPsrQhpnJh","timestamp":1622024945852}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyPLQZyvgCedi9Ups8HKOBh0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ajOx2WcZ_uLO"},"source":["# Procedural"]},{"cell_type":"markdown","metadata":{"id":"onNkqotk_zFo"},"source":["Mount my drive and create a folder for the data if it doesn't already exist"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PalDdmCx_fAe","executionInfo":{"status":"ok","timestamp":1622042712249,"user_tz":-60,"elapsed":253,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"89094177-1cb7-42bd-b5ee-bf323902521d"},"source":["# Mount my drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Create a folder for the data if it does not already exist\n","import os\n","if not os.path.exists('/content/drive/MyDrive/MastersProject/data/'):\n","    os.makedirs('/content/drive/MyDrive/MastersProject/data/')\n","    print(\"Created the folder!\")\n","else:\n","    print(\"Folder already existed!\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Folder already existed!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EHXD3NBE_3Rh","executionInfo":{"status":"ok","timestamp":1622042715878,"user_tz":-60,"elapsed":3468,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"567b1eba-a41d-43ed-bf0b-a24998cfa671"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z_nZLxKc_9Hq","executionInfo":{"status":"ok","timestamp":1622042716449,"user_tz":-60,"elapsed":575,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["import transformers\n","import pandas as pd\n","import torch\n","import numpy as np\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"4h2T_rfc_-p4","executionInfo":{"status":"ok","timestamp":1622042716449,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["RANDOM_SEED = 42"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fMoE3JDpAhTN"},"source":["# Prepare the data for BERT"]},{"cell_type":"markdown","metadata":{"id":"wzRHz8D3Ax-e"},"source":["Set the hyperparameters needed for data preparation"]},{"cell_type":"code","metadata":{"id":"gd78Vo-EAkKp","executionInfo":{"status":"ok","timestamp":1622042716450,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["MODEL_NAME = \"bert-base-cased\"\n","MAX_LEN = 512\n","VALID_TEST_PROPORTION = 0.2\n","BATCH_SIZE = 4339"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UOoMBnWaBFuK"},"source":["Read the dataset as a pandas dataframe"]},{"cell_type":"code","metadata":{"id":"grZGRxenBFN_","executionInfo":{"status":"ok","timestamp":1622042718549,"user_tz":-60,"elapsed":2103,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["df = pd.read_csv('drive/MyDrive/MastersProject/data/aita_clean.csv')\n","df['text'] = df[\"title\"] + \" \" + df[\"body\"].fillna(\"\")"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UjOi1pn1BNPm"},"source":["Specify the BERT dataset class"]},{"cell_type":"code","metadata":{"id":"hcP8QgoqBJER","executionInfo":{"status":"ok","timestamp":1622042718550,"user_tz":-60,"elapsed":7,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["class AITADataset(Dataset):\n","    # Upon onject instance creation, you feed the text samples, their targets, the tokeniser and the max length.\n","    def __init__(self, texts, targets, tokeniser, max_len):\n","        self.texts = texts\n","        self.targets = targets\n","        self.tokeniser = tokeniser\n","        self.max_len = max_len\n","        \n","    def __len__(self):\n","        return len(self.texts)\n","    \n","    # This method is called when a batch is created. \"item\" is the index of each sample to be in batch.\n","    def __getitem__(self, item):\n","        # Normally it is already a string\n","        text = str(self.texts[item])\n","\n","        # Create a dictionary constituting the encoding of the current item (i.e. current text)\n","        encoding = tokeniser(\n","            text,\n","            truncation=True,\n","            max_length=self.max_len,\n","            add_special_tokens=True,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_token_type_ids=False,\n","            return_tensors='pt')\n","        \n","        # These are unnecessary I think\n","        encoding['input_ids'] = encoding['input_ids'].flatten()\n","        encoding['attention_mask'] = encoding['attention_mask'].flatten()\n","        \n","        # In the encoding dictionary for the current text, add the target corresponding to it and the actual test\n","        dic_out = {'input_ids': encoding['input_ids'],\n","                   'attention_mask': encoding['attention_mask'],\n","                   'targets': torch.tensor(self.targets[item], dtype=torch.long),\n","                   'sample_text': text}\n","        \n","        return dic_out"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yQFyFTkVBV3q"},"source":["Make a function that creates a dataloader for BERT"]},{"cell_type":"code","metadata":{"id":"ybmH7DKyBVT4","executionInfo":{"status":"ok","timestamp":1622042718551,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["def create_data_loader(df, tokeniser, max_len, batch_size):\n","    '''\n","    Creates a dataset from the given dataframe and a dataloader spitting batches of the dataset\n","    '''\n","    ds = AITADataset(\n","        texts=df.text.to_numpy(),\n","        targets=df.is_asshole.to_numpy(),\n","        tokeniser=tokeniser,\n","        max_len=max_len)\n","    \n","    dataloader = DataLoader(ds, batch_size=batch_size, num_workers=2)\n","    \n","    return dataloader"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"orS5SeVQBeVQ"},"source":["Split the dataframes"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PC9b5wQHBcZv","executionInfo":{"status":"ok","timestamp":1622042718815,"user_tz":-60,"elapsed":269,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"e49af2c3-7494-43b0-f640-34ae32492166"},"source":["df_train_big, df_test_valid = train_test_split(df, test_size=VALID_TEST_PROPORTION, random_state=RANDOM_SEED)\n","df_train_1_2_3_4, df_train_5_6 = train_test_split(df_train_big, test_size=1/3, random_state=RANDOM_SEED)\n","df_train_1_2, df_train_3_4 = train_test_split(df_train_1_2_3_4, test_size=0.5, random_state=RANDOM_SEED)\n","df_train_5, df_train_6 = train_test_split(df_train_5_6, test_size=0.5, random_state=RANDOM_SEED)\n","df_train_1, df_train_2 = train_test_split(df_train_1_2, test_size=0.5, random_state=RANDOM_SEED)\n","df_train_3, df_train_4 = train_test_split(df_train_3_4, test_size=0.5, random_state=RANDOM_SEED)\n","\n","df_valid, df_test = train_test_split(df_test_valid, test_size=0.5, random_state=RANDOM_SEED)\n","print(\"Train dataset big:\", df_train_big.shape)\n","print(\"Train dataset 1:\", df_train_1.shape)\n","print(\"Train dataset 2:\", df_train_2.shape)\n","print(\"Train dataset 3:\", df_train_3.shape)\n","print(\"Train dataset 4:\", df_train_4.shape)\n","print(\"Train dataset 5:\", df_train_5.shape)\n","print(\"Train dataset 6:\", df_train_6.shape)\n","print(\"Valid dataset:\", df_valid.shape)\n","print(\"Test dataset:\", df_test.shape)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Train dataset big: (78102, 10)\n","Train dataset 1: (13017, 10)\n","Train dataset 2: (13017, 10)\n","Train dataset 3: (13017, 10)\n","Train dataset 4: (13017, 10)\n","Train dataset 5: (13017, 10)\n","Train dataset 6: (13017, 10)\n","Valid dataset: (9763, 10)\n","Test dataset: (9763, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-Qw7HOAc_AUZ"},"source":["Save the targets and weights of the dataset split as above"]},{"cell_type":"code","metadata":{"id":"spg1Cdrq--xC","executionInfo":{"status":"ok","timestamp":1622042718815,"user_tz":-60,"elapsed":2,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["y_train_1 = torch.tensor(df_train_1['is_asshole'].values, dtype=torch.short)\n","torch.save(y_train_1, '/content/drive/MyDrive/MastersProject/BERT_outputs/split_in_6/y_train_1.pt')\n","del y_train_1\n","\n","y_train_2 = torch.tensor(df_train_2['is_asshole'].values, dtype=torch.short)\n","torch.save(y_train_2, '/content/drive/MyDrive/MastersProject/BERT_outputs/split_in_6/y_train_2.pt')\n","del y_train_2\n","\n","y_train_3 = torch.tensor(df_train_3['is_asshole'].values, dtype=torch.short)\n","torch.save(y_train_3, '/content/drive/MyDrive/MastersProject/BERT_outputs/split_in_6/y_train_3.pt')\n","del y_train_3\n","\n","y_train_4 = torch.tensor(df_train_4['is_asshole'].values, dtype=torch.short)\n","torch.save(y_train_4, '/content/drive/MyDrive/MastersProject/BERT_outputs/split_in_6/y_train_4.pt')\n","del y_train_4\n","\n","y_train_5 = torch.tensor(df_train_5['is_asshole'].values, dtype=torch.short)\n","torch.save(y_train_5, '/content/drive/MyDrive/MastersProject/BERT_outputs/split_in_6/y_train_5.pt')\n","del y_train_5\n","\n","y_train_6 = torch.tensor(df_train_6['is_asshole'].values, dtype=torch.short)\n","torch.save(y_train_6, '/content/drive/MyDrive/MastersProject/BERT_outputs/split_in_6/y_train_6.pt')\n","del y_train_6\n","\n","y_valid = torch.tensor(df_valid['is_asshole'].values, dtype=torch.short)\n","torch.save(y_valid, '/content/drive/MyDrive/MastersProject/BERT_outputs/split_in_6/_valid.pt')\n","del y_valid\n","\n","y_test = torch.tensor(df_test['is_asshole'].values, dtype=torch.short)\n","torch.save(y_test, '/content/drive/MyDrive/MastersProject/BERT_outputs/split_in_6/y_test.pt')\n","del y_test"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yhEYAEqyCkNu"},"source":["Initialise the BERT tokeniser based on the chosen model name"]},{"cell_type":"code","metadata":{"id":"6lpBIPbCCSmV","executionInfo":{"status":"ok","timestamp":1622042720346,"user_tz":-60,"elapsed":1533,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["tokeniser = transformers.BertTokenizer.from_pretrained(MODEL_NAME)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ISNXmhyHCqcC"},"source":["Create a dataloader from the small dataframe to be overfit"]},{"cell_type":"code","metadata":{"id":"oCVNJMz2CrPz","executionInfo":{"status":"ok","timestamp":1622042720348,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["train_loader_big = create_data_loader(df_train_big, tokeniser, MAX_LEN, BATCH_SIZE)\n","train_loader_1 = create_data_loader(df_train_1, tokeniser, MAX_LEN, BATCH_SIZE)\n","train_loader_2 = create_data_loader(df_train_2, tokeniser, MAX_LEN, BATCH_SIZE)\n","train_loader_3 = create_data_loader(df_train_3, tokeniser, MAX_LEN, BATCH_SIZE)\n","train_loader_4 = create_data_loader(df_train_3, tokeniser, MAX_LEN, BATCH_SIZE)\n","train_loader_5 = create_data_loader(df_train_3, tokeniser, MAX_LEN, BATCH_SIZE)\n","train_loader_6 = create_data_loader(df_train_3, tokeniser, MAX_LEN, BATCH_SIZE)\n","valid_loader = create_data_loader(df_valid, tokeniser, MAX_LEN, BATCH_SIZE)\n","test_loader = create_data_loader(df_test, tokeniser, MAX_LEN, BATCH_SIZE)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i4dcOU87DUVO"},"source":["Inspect a batch from the dataloader"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KU9IHW-Cskm","executionInfo":{"status":"ok","timestamp":1622042754147,"user_tz":-60,"elapsed":33803,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"f39ef2a8-0db5-49b4-8b4b-1670c1b80180"},"source":["num_tokens_to_print_per_text = 100\n","train_data_batch = next(iter(train_loader_1))\n","loader_keys = train_data_batch.keys()\n","print(\"Each dataloader batch is like a dictionary with keys:\", loader_keys)\n","print(100*\"-\")\n","print(\"Shapes:\")\n","print()\n","print(\"input_ids:         \", train_data_batch['input_ids'].shape)\n","print(\"attention_mask:    \", train_data_batch['attention_mask'].shape)\n","print(\"targets:           \", train_data_batch['targets'].shape)\n","print(\"sample_text:       \", train_data_batch['targets'].shape)\n","print(100*\"-\")\n","print(\"Here are the first {} tokens of the first 5 tokenised texts in the batch:\".format(num_tokens_to_print_per_text))\n","print()\n","for i in range(0, 5):\n","  current_sample_token_ids = train_data_batch['input_ids'][i,0:num_tokens_to_print_per_text]\n","  current_sample_tokens = tokeniser.convert_ids_to_tokens(current_sample_token_ids)\n","  print(current_sample_tokens)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Each dataloader batch is like a dictionary with keys: dict_keys(['input_ids', 'attention_mask', 'targets', 'sample_text'])\n","----------------------------------------------------------------------------------------------------\n","Shapes:\n","\n","input_ids:          torch.Size([4339, 512])\n","attention_mask:     torch.Size([4339, 512])\n","targets:            torch.Size([4339])\n","sample_text:        torch.Size([4339])\n","----------------------------------------------------------------------------------------------------\n","Here are the first 100 tokens of the first 5 tokenised texts in the batch:\n","\n","['[CLS]', 'AI', '##TA', 'for', 'not', 'letting', 'my', 'neighbor', 'from', 'the', 'building', 'next', 'door', 'climb', 'M', '##Y', 'roof', 'T', '##LD', '##R', 'at', 'bottom', 'I', '’', 'm', 'on', 'mobile', 'and', 'I', '’', 'm', 'also', 'angry', 'typing', 'So', 'I', 'live', 'in', 'a', 'big', 'city', 'in', 'a', 'very', 'lively', 'neighborhood', '.', 'I', 'live', 'across', 'from', 'bars', ',', 'strip', 'clubs', ',', 'live', 'music', '.', '.', '.', 'it', '’', 's', 'great', '.', 'That', 'being', 'said', ',', 'I', 'know', 'that', 'there', 'will', 'be', 'noise', 'from', 'neighbors', ',', 'and', 'I', '’', 'm', 'totally', 'fine', 'with', 'that', 'to', 'a', 'certain', 'extent', '.', 'The', 'building', 'next', 'door', 'has', '4', 'units']\n","['[CLS]', 'AI', '##TA', 'for', 'having', 'unconventional', 'religious', 'beliefs', ',', 'and', 'being', 'honest', 'about', 'them', 'when', 'asked', '.', 'Hey', 'red', '##dit', ',', 'I', \"'\", 'm', 'going', 'to', 'try', 'to', 'cover', 'everything', 'without', 'sounding', 'pre', '##ach', '##y', 'or', 'ad', '##hering', 'to', 'stereotypes', '.', 'Ever', 'since', 'I', 'was', 'a', 'kid', 'I', \"'\", 've', 'been', 'completely', 'incapable', 'of', 'harm', '##ing', 'animals', ',', 'even', 'ones', 'some', 'people', 'see', 'as', 'lesser', 'like', 'bugs', 'or', 'rode', '##nts', '.', 'I', 'ate', 'meat', 'as', 'it', 'was', 'how', 'I', 'was', 'brought', 'up', 'but', 'if', 'I', 'was', 'ever', 'confronted', 'about', 'me', 'being', 'an', 'animal', 'lover', 'I', 'would', 'find', 'myself', 'wrought', 'with']\n","['[CLS]', 'AI', '##TA', 'for', 'b', '##ashi', '##ng', 'the', 'town', 'I', 'grew', 'up', 'in', 'when', 'my', 'family', 'still', 'lives', 'there', '?', 'AI', '##TA', 'for', 'talking', 'smack', 'about', 'my', 'hometown', 'when', 'my', 'siblings', 'still', 'live', 'there', '?', 'Background', ':', 'my', 'partner', 'and', 'I', 'are', 'the', 'oldest', 'of', 'our', 'respective', 'siblings', '(', 'we', 'each', 'have', 'a', 'few', ')', '.', 'We', 'married', 'later', 'than', 'all', 'of', 'them', '.', 'On', 'my', 'side', 'it', 'was', 'a', 'full', 'decade', 'of', 'smug', 'married', 'BS', 'from', 'my', 'siblings', 'who', 'at', 'every', 'turn', 'would', 'make', 'comments', 'to', 'me', 'like', '“', 'you', 'don', '’', 't', 'understand', 'b', '##c', 'you', '’', 're']\n","['[CLS]', 'W', '##IB', '##TA', 'If', 'I', 'file', 'a', 'complaint', 'about', 'our', 'mater', '##nity', 'nurse', '?', 'Wife', 'gave', 'birth', 'to', 'our', 'first', 'child', 'last', 'week', ',', 'mom', 'and', 'baby', 'are', 'happy', ',', 'healthy', ',', 'doing', 'great', '.', 'The', 'delivery', 'mostly', 'went', 'very', 'smooth', ',', 'but', 'some', 'comments', 'and', 'reactions', 'from', 'the', 'mater', '##nity', 'nurse', 'really', 'rubbed', 'me', 'the', 'wrong', 'way', '.', 'The', 'thing', 'is', 'I', '’', 've', 'never', 'been', 'in', 'a', 'room', 'where', 'a', 'baby', 'is', 'being', 'delivered', 'before', 'so', 'don', '’', 't', 'know', 'if', 'my', 'wife', '’', 's', 'behavior', 'was', 'abnormal', 'and', 'the', 'nurse', 'was', 'responding', 'to', 'that', 'or', 'if']\n","['[CLS]', 'AI', '##TA', 'for', 'banning', 'hair', 'dying', 'in', 'our', 'house', '?', 'So', 'I', 'rent', 'out', 'a', 'house', 'with', 'Room', '##ie', 'A', 'and', 'Room', '##ie', 'B', '.', 'Room', '##ie', 'A', 'has', 'the', 'master', 'bedroom', ',', 'and', 'her', 'own', 'massive', 'bathroom', '.', 'Room', '##ie', 'B', 'and', 'I', 'share', 'the', 'hall', 'bathroom', ',', 'which', 'is', 'directly', 'in', 'front', 'of', 'the', 'door', 'to', 'my', 'room', '.', 'Room', '##ie', 'A', 'had', 'Friend', 'over', 'yesterday', 'and', 'they', 'decided', 'to', 'dye', 'her', 'hair', 'purple', '.', 'Neither', 'had', 'ever', 'done', 'this', 'before', 'or', 'let', 'the', 'other', 'house', '##mates', 'know', 'this', 'was', 'happening', 'until', 'it', 'was', 'already', 'in', 'progress']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7MbLr0DWEZEt"},"source":["# Create BERT and send the primary data through it"]},{"cell_type":"markdown","metadata":{"id":"YGauZtSlEjMg"},"source":["Use GPU if available"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9suKi99jDfgB","executionInfo":{"status":"ok","timestamp":1622042754148,"user_tz":-60,"elapsed":10,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"086d61e7-b18b-4dac-e7c9-221ccbc66659"},"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","torch.cuda.empty_cache()\n","print(device)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kYnHMJY0EnpH"},"source":["Instantiate BERT using a custom configuration and freeze it"]},{"cell_type":"code","metadata":{"id":"Gt3szaceElEa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622042761406,"user_tz":-60,"elapsed":7267,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"92a7f17f-b5d5-45d8-cd19-9c8c29f53147"},"source":["bert_config = transformers.BertConfig(vocab_size=28996,\n","                                      hidden_size=768,\n","                                      num_hidden_layers=12,\n","                                      num_attention_heads=12,\n","                                      max_position_embeddings=MAX_LEN)\n","\n","bert_model = transformers.BertModel.from_pretrained(MODEL_NAME, config=bert_config)\n","# Freeze BERT so that its weights are not further fine-tuned from their pretrained values and when samples are passed into it, grads are not stored in the RAM\n","for param in bert_model.parameters():\n","    param.requires_grad = False\n","bert_model = bert_model.to(device)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"yRYe5VcerP4f"},"source":["Get BERT's pooled output for the training/validation/test data"]},{"cell_type":"code","metadata":{"id":"2dNRt4VStQXd","executionInfo":{"status":"ok","timestamp":1622042761408,"user_tz":-60,"elapsed":18,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["data_to_get = \"train_3\"             # In {train_big, train_1, train_2, train_3, test, valid}\n","pooled_or_unpooled = \"unpooled\"     # In {pooled, unpooled}"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBfV6yfC2Mqg","executionInfo":{"status":"ok","timestamp":1622042761408,"user_tz":-60,"elapsed":16,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["!rm -rf /usr/local/lib/python2.7\n","!rm -rf /swift\n","!rm -rf /tensorflow-2.0.0"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":788},"id":"35RCPRqFFqbp","executionInfo":{"status":"error","timestamp":1622042795729,"user_tz":-60,"elapsed":34334,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}},"outputId":"b641c8f3-0ef7-401b-baa3-601d0302f3f5"},"source":["# Choose whether to feed the batches of the train, valid or test loader to BERT\n","if data_to_get == \"test\":\n","    loader = test_loader\n","elif data_to_get == \"train_big\":\n","    loader = train_loader_big\n","elif data_to_get == \"train_1\":\n","    loader = train_loader_1\n","elif data_to_get == \"train_2\":\n","    loader = train_loader_2\n","elif data_to_get == \"train_3\":\n","    loader = train_loader_3\n","elif data_to_get == \"train_4\":\n","    loader = train_loader_4\n","elif data_to_get == \"train_5\":\n","    loader = train_loader_5\n","elif data_to_get == \"train_6\":\n","    loader = train_loader_6\n","elif data_to_get == \"valid\":\n","    loader = valid_loader\n","else:\n","    raise ValueError (\"Invalid data_to_get selected\")\n","\n","del test_loader\n","del train_loader_big\n","del train_loader_1\n","del train_loader_2\n","del train_loader_3\n","del train_loader_4\n","del train_loader_5\n","del train_loader_6\n","del valid_loader\n","\n","for i, data_batch in enumerate(loader):\n","    bert_output = bert_model(data_batch['input_ids'].to(device), data_batch['attention_mask'].to(device))\n","\n","    if 'X' not in globals():\n","        if pooled_or_unpooled == \"pooled\":\n","            X = bert_output['pooler_output']\n","        elif pooled_or_unpooled == \"unpooled\":\n","            X = bert_output['last_hidden_state']\n","        else:\n","            raise ValueError\n","    else:\n","        print(\"yei!\")\n","        if pooled_or_unpooled == \"pooled\":\n","            X = torch.cat((X, bert_output['pooler_output']), 0)\n","        elif pooled_or_unpooled == \"unpooled\":\n","            X = torch.cat((X, bert_output['last_hidden_state']), 0)\n","        else:\n","            raise ValueError\n","\n","    del bert_output\n","    torch.cuda.empty_cache()\n","\n","    print(\"Batch #{} through!\".format(i + 1))\n","\n","    torch.save(X.half(), '/content/drive/MyDrive/MastersProject/BERT_outputs/split_in_6/X_{}_{}_{}th4339.pt'.format(data_to_get, pooled_or_unpooled, i+1))\n","    del X\n","    torch.cuda.empty_cache()"],"execution_count":18,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-5fc8a123b008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'X'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m         )\n\u001b[1;32m    971\u001b[0m         encoder_outputs = self.encoder(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 6.36 GiB (GPU 0; 15.90 GiB total capacity; 13.17 GiB already allocated; 1.80 GiB free; 13.23 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"WN9eyHR5i76S","executionInfo":{"status":"aborted","timestamp":1622042795728,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ion Stagkos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgj4rUVcMhEW9tY5Cj_SZo8Aj2dbXQta6pzdGcg=s64","userId":"00279017017823147531"}}},"source":["# torch.save(X, '/content/drive/MyDrive/MastersProject/BERT_outputs/X_{}_{}.pt'.format(data_to_get, pooled_or_unpooled))\n","# to load: X_train_pooled = torch.load('/content/drive/MyDrive/MastersProject/BERT_outputs/X_train_pooled.pt', map_location=torch.device('cpu'))"],"execution_count":null,"outputs":[]}]}